<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Kafka Connect深度解读之错误处理和死信队列 | Apache Ignite技术服务</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="stylesheet" href="/css/plugin.css">
    <link rel="stylesheet" href="/css/style.css">
    <link rel="stylesheet" href="/css/font-awesome.min.css">
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico">
    <script src="https://hm.baidu.com/hm.js?76e2d8c51e8068e025053bc59d51045b"></script>
    <meta name="description" content="apache ignite,ignite中文,ignite官网,内存数据库,分布式数据库">
    <meta name="keywords" content="apache ignite,ignite中文,ignite官网,内存数据库,分布式数据库">
    <meta http-equiv="cache-control" content="no-store,no-cache,must-revalidate">
    <meta http-equiv="expires" content="0">
    
    <link rel="preload" href="/assets/css/0.styles.cb5acd6d.css" as="style"><link rel="preload" href="/assets/js/app.12c4309e.js" as="script"><link rel="preload" href="/assets/js/3.b95bc49f.js" as="script"><link rel="preload" href="/assets/js/1.5c509afc.js" as="script"><link rel="preload" href="/assets/js/32.81d53af7.js" as="script"><link rel="preload" href="/assets/js/8.85f43835.js" as="script"><link rel="prefetch" href="/assets/js/10.41a5f603.js"><link rel="prefetch" href="/assets/js/100.8dd9717f.js"><link rel="prefetch" href="/assets/js/101.a0895512.js"><link rel="prefetch" href="/assets/js/102.d184e2e5.js"><link rel="prefetch" href="/assets/js/103.206d714d.js"><link rel="prefetch" href="/assets/js/104.830b7843.js"><link rel="prefetch" href="/assets/js/105.fec64e0c.js"><link rel="prefetch" href="/assets/js/106.63a0feb4.js"><link rel="prefetch" href="/assets/js/107.f6c1d245.js"><link rel="prefetch" href="/assets/js/108.fa7dc6fb.js"><link rel="prefetch" href="/assets/js/109.ba42d128.js"><link rel="prefetch" href="/assets/js/11.2830eec0.js"><link rel="prefetch" href="/assets/js/110.c0abfd0b.js"><link rel="prefetch" href="/assets/js/111.67f9b0c9.js"><link rel="prefetch" href="/assets/js/112.70946bf2.js"><link rel="prefetch" href="/assets/js/113.577cabc9.js"><link rel="prefetch" href="/assets/js/114.7041afe6.js"><link rel="prefetch" href="/assets/js/115.79f0dcf4.js"><link rel="prefetch" href="/assets/js/116.aeea4b46.js"><link rel="prefetch" href="/assets/js/117.04ef6a4c.js"><link rel="prefetch" href="/assets/js/118.baa95c9a.js"><link rel="prefetch" href="/assets/js/119.d10f5729.js"><link rel="prefetch" href="/assets/js/12.3d2f4947.js"><link rel="prefetch" href="/assets/js/120.c970ae55.js"><link rel="prefetch" href="/assets/js/121.8d02ceb6.js"><link rel="prefetch" href="/assets/js/122.2c220215.js"><link rel="prefetch" href="/assets/js/123.a44f5c84.js"><link rel="prefetch" href="/assets/js/124.e3bcc450.js"><link rel="prefetch" href="/assets/js/125.1051932f.js"><link rel="prefetch" href="/assets/js/126.eb24abfb.js"><link rel="prefetch" href="/assets/js/127.d1f06d97.js"><link rel="prefetch" href="/assets/js/128.16b91a56.js"><link rel="prefetch" href="/assets/js/129.e21c84ab.js"><link rel="prefetch" href="/assets/js/13.1af33d82.js"><link rel="prefetch" href="/assets/js/130.29755fdf.js"><link rel="prefetch" href="/assets/js/131.105a3bb1.js"><link rel="prefetch" href="/assets/js/132.7e11a37f.js"><link rel="prefetch" href="/assets/js/133.75ef80d7.js"><link rel="prefetch" href="/assets/js/134.544a3fad.js"><link rel="prefetch" href="/assets/js/135.df2fc742.js"><link rel="prefetch" href="/assets/js/136.2dbba136.js"><link rel="prefetch" href="/assets/js/137.ccce2d8f.js"><link rel="prefetch" href="/assets/js/138.037626e6.js"><link rel="prefetch" href="/assets/js/139.a9cfc5d7.js"><link rel="prefetch" href="/assets/js/14.1dc71b94.js"><link rel="prefetch" href="/assets/js/140.7db27260.js"><link rel="prefetch" href="/assets/js/141.4273f161.js"><link rel="prefetch" href="/assets/js/142.7941ca41.js"><link rel="prefetch" href="/assets/js/143.0665f716.js"><link rel="prefetch" href="/assets/js/144.f4f5e178.js"><link rel="prefetch" href="/assets/js/145.1ae0ceb8.js"><link rel="prefetch" href="/assets/js/146.0f695b3a.js"><link rel="prefetch" href="/assets/js/147.3a5a0c1e.js"><link rel="prefetch" href="/assets/js/148.7b50379e.js"><link rel="prefetch" href="/assets/js/149.c8cf04ca.js"><link rel="prefetch" href="/assets/js/15.7df0b63f.js"><link rel="prefetch" href="/assets/js/150.05fbfa01.js"><link rel="prefetch" href="/assets/js/151.93950ff9.js"><link rel="prefetch" href="/assets/js/152.d13d95e5.js"><link rel="prefetch" href="/assets/js/153.281611b0.js"><link rel="prefetch" href="/assets/js/154.4bd2d79c.js"><link rel="prefetch" href="/assets/js/155.0e121f37.js"><link rel="prefetch" href="/assets/js/156.ae6224da.js"><link rel="prefetch" href="/assets/js/157.60c9c1d0.js"><link rel="prefetch" href="/assets/js/158.25948f55.js"><link rel="prefetch" href="/assets/js/159.b3e504a0.js"><link rel="prefetch" href="/assets/js/16.14c9b590.js"><link rel="prefetch" href="/assets/js/160.5957a68f.js"><link rel="prefetch" href="/assets/js/161.55fdd524.js"><link rel="prefetch" href="/assets/js/162.f55dd01a.js"><link rel="prefetch" href="/assets/js/163.417d5be2.js"><link rel="prefetch" href="/assets/js/164.52520ea2.js"><link rel="prefetch" href="/assets/js/165.f8e0913d.js"><link rel="prefetch" href="/assets/js/166.89c13b2d.js"><link rel="prefetch" href="/assets/js/167.31d3e0db.js"><link rel="prefetch" href="/assets/js/168.6fec639a.js"><link rel="prefetch" href="/assets/js/169.11d38c5f.js"><link rel="prefetch" href="/assets/js/17.25a2bd2e.js"><link rel="prefetch" href="/assets/js/170.9842e337.js"><link rel="prefetch" href="/assets/js/171.ae9b256f.js"><link rel="prefetch" href="/assets/js/172.cf64f18d.js"><link rel="prefetch" href="/assets/js/173.ee7a0176.js"><link rel="prefetch" href="/assets/js/174.573efb18.js"><link rel="prefetch" href="/assets/js/175.696259d2.js"><link rel="prefetch" href="/assets/js/176.a330d4b7.js"><link rel="prefetch" href="/assets/js/177.12a9a23a.js"><link rel="prefetch" href="/assets/js/178.5c6fdaa9.js"><link rel="prefetch" href="/assets/js/179.16a96ace.js"><link rel="prefetch" href="/assets/js/18.c43a3e2d.js"><link rel="prefetch" href="/assets/js/180.17e02e51.js"><link rel="prefetch" href="/assets/js/181.75466724.js"><link rel="prefetch" href="/assets/js/182.59757147.js"><link rel="prefetch" href="/assets/js/183.e20cef4b.js"><link rel="prefetch" href="/assets/js/184.60d1db45.js"><link rel="prefetch" href="/assets/js/185.318657ff.js"><link rel="prefetch" href="/assets/js/186.39273304.js"><link rel="prefetch" href="/assets/js/187.896ee339.js"><link rel="prefetch" href="/assets/js/188.829cedd7.js"><link rel="prefetch" href="/assets/js/189.29229d20.js"><link rel="prefetch" href="/assets/js/19.63a325b3.js"><link rel="prefetch" href="/assets/js/190.ee776c74.js"><link rel="prefetch" href="/assets/js/191.be5a24df.js"><link rel="prefetch" href="/assets/js/192.75b42a1c.js"><link rel="prefetch" href="/assets/js/193.f540edf3.js"><link rel="prefetch" href="/assets/js/194.d954b6b7.js"><link rel="prefetch" href="/assets/js/195.10582fd9.js"><link rel="prefetch" href="/assets/js/196.84b3f460.js"><link rel="prefetch" href="/assets/js/197.5f557681.js"><link rel="prefetch" href="/assets/js/198.1e89f134.js"><link rel="prefetch" href="/assets/js/199.fc3a3c6c.js"><link rel="prefetch" href="/assets/js/20.d556936a.js"><link rel="prefetch" href="/assets/js/200.80b9b103.js"><link rel="prefetch" href="/assets/js/201.9fad2173.js"><link rel="prefetch" href="/assets/js/202.e9da18b7.js"><link rel="prefetch" href="/assets/js/203.ff8e8eb7.js"><link rel="prefetch" href="/assets/js/204.05ae9f6f.js"><link rel="prefetch" href="/assets/js/205.00392078.js"><link rel="prefetch" href="/assets/js/206.49174d6a.js"><link rel="prefetch" href="/assets/js/207.11535285.js"><link rel="prefetch" href="/assets/js/208.33cd493d.js"><link rel="prefetch" href="/assets/js/209.af0428c0.js"><link rel="prefetch" href="/assets/js/21.55a0b721.js"><link rel="prefetch" href="/assets/js/210.71317685.js"><link rel="prefetch" href="/assets/js/211.d150b8e4.js"><link rel="prefetch" href="/assets/js/212.a93805d6.js"><link rel="prefetch" href="/assets/js/213.db4fdfa9.js"><link rel="prefetch" href="/assets/js/214.a410b70d.js"><link rel="prefetch" href="/assets/js/215.a9a37472.js"><link rel="prefetch" href="/assets/js/216.43428d49.js"><link rel="prefetch" href="/assets/js/217.3083f7e0.js"><link rel="prefetch" href="/assets/js/218.79774c74.js"><link rel="prefetch" href="/assets/js/219.7feb22cb.js"><link rel="prefetch" href="/assets/js/22.e1ae2ebc.js"><link rel="prefetch" href="/assets/js/220.9fa4386a.js"><link rel="prefetch" href="/assets/js/221.73424581.js"><link rel="prefetch" href="/assets/js/222.c376f839.js"><link rel="prefetch" href="/assets/js/223.a624c75e.js"><link rel="prefetch" href="/assets/js/224.3088ef41.js"><link rel="prefetch" href="/assets/js/225.4af58ce1.js"><link rel="prefetch" href="/assets/js/226.7d41380a.js"><link rel="prefetch" href="/assets/js/227.89a8090e.js"><link rel="prefetch" href="/assets/js/228.7ab726e0.js"><link rel="prefetch" href="/assets/js/229.1a592e36.js"><link rel="prefetch" href="/assets/js/23.208f00a1.js"><link rel="prefetch" href="/assets/js/230.b3d14c50.js"><link rel="prefetch" href="/assets/js/231.e171eef9.js"><link rel="prefetch" href="/assets/js/232.9603b05f.js"><link rel="prefetch" href="/assets/js/233.1af90bd1.js"><link rel="prefetch" href="/assets/js/234.62a96b95.js"><link rel="prefetch" href="/assets/js/235.906142b0.js"><link rel="prefetch" href="/assets/js/236.972eeb66.js"><link rel="prefetch" href="/assets/js/237.ae296352.js"><link rel="prefetch" href="/assets/js/238.f06e1988.js"><link rel="prefetch" href="/assets/js/239.1600d1b5.js"><link rel="prefetch" href="/assets/js/24.11c40bca.js"><link rel="prefetch" href="/assets/js/240.e2557f3a.js"><link rel="prefetch" href="/assets/js/241.c6173be3.js"><link rel="prefetch" href="/assets/js/242.1c501e19.js"><link rel="prefetch" href="/assets/js/243.f8a24041.js"><link rel="prefetch" href="/assets/js/244.91cb6d4b.js"><link rel="prefetch" href="/assets/js/245.23b659f9.js"><link rel="prefetch" href="/assets/js/246.e4bfffdb.js"><link rel="prefetch" href="/assets/js/247.95e52d7c.js"><link rel="prefetch" href="/assets/js/248.3e1f304f.js"><link rel="prefetch" href="/assets/js/249.0be32375.js"><link rel="prefetch" href="/assets/js/25.4b26eb08.js"><link rel="prefetch" href="/assets/js/250.18a0bb8b.js"><link rel="prefetch" href="/assets/js/251.3d9fe1e2.js"><link rel="prefetch" href="/assets/js/252.ef6b4e52.js"><link rel="prefetch" href="/assets/js/253.8277f2f3.js"><link rel="prefetch" href="/assets/js/254.f1f2e575.js"><link rel="prefetch" href="/assets/js/255.98a92f16.js"><link rel="prefetch" href="/assets/js/256.b1c466f9.js"><link rel="prefetch" href="/assets/js/257.ebc8b82e.js"><link rel="prefetch" href="/assets/js/258.f420312d.js"><link rel="prefetch" href="/assets/js/259.c44b4688.js"><link rel="prefetch" href="/assets/js/26.99794fbc.js"><link rel="prefetch" href="/assets/js/260.aad073d3.js"><link rel="prefetch" href="/assets/js/261.93724a0f.js"><link rel="prefetch" href="/assets/js/262.9c8f3124.js"><link rel="prefetch" href="/assets/js/263.3c21a494.js"><link rel="prefetch" href="/assets/js/264.7dea16a3.js"><link rel="prefetch" href="/assets/js/265.97f14e11.js"><link rel="prefetch" href="/assets/js/266.407ef4eb.js"><link rel="prefetch" href="/assets/js/267.f910742d.js"><link rel="prefetch" href="/assets/js/268.7b2dc949.js"><link rel="prefetch" href="/assets/js/269.729e229c.js"><link rel="prefetch" href="/assets/js/27.a023f451.js"><link rel="prefetch" href="/assets/js/270.e06db73a.js"><link rel="prefetch" href="/assets/js/271.0d75fce6.js"><link rel="prefetch" href="/assets/js/272.5a354cea.js"><link rel="prefetch" href="/assets/js/273.74980d47.js"><link rel="prefetch" href="/assets/js/274.810bb14e.js"><link rel="prefetch" href="/assets/js/275.d99403e6.js"><link rel="prefetch" href="/assets/js/276.ebf9863d.js"><link rel="prefetch" href="/assets/js/277.0693bd98.js"><link rel="prefetch" href="/assets/js/278.33e1ca18.js"><link rel="prefetch" href="/assets/js/279.dfb60af3.js"><link rel="prefetch" href="/assets/js/28.76a90833.js"><link rel="prefetch" href="/assets/js/280.b82729a5.js"><link rel="prefetch" href="/assets/js/281.29063d6e.js"><link rel="prefetch" href="/assets/js/282.2a6dc89f.js"><link rel="prefetch" href="/assets/js/283.8e33df1e.js"><link rel="prefetch" href="/assets/js/284.3dd72758.js"><link rel="prefetch" href="/assets/js/285.0d2ac2af.js"><link rel="prefetch" href="/assets/js/286.4d220ecc.js"><link rel="prefetch" href="/assets/js/287.7cf1c62d.js"><link rel="prefetch" href="/assets/js/288.5bb59006.js"><link rel="prefetch" href="/assets/js/289.4d0fa470.js"><link rel="prefetch" href="/assets/js/29.f0f4d791.js"><link rel="prefetch" href="/assets/js/290.a8d75321.js"><link rel="prefetch" href="/assets/js/291.167bab79.js"><link rel="prefetch" href="/assets/js/292.4cba9be2.js"><link rel="prefetch" href="/assets/js/293.20d49f44.js"><link rel="prefetch" href="/assets/js/294.27a43207.js"><link rel="prefetch" href="/assets/js/295.35a94f3a.js"><link rel="prefetch" href="/assets/js/30.ed97af1f.js"><link rel="prefetch" href="/assets/js/31.f464b981.js"><link rel="prefetch" href="/assets/js/33.1abe3576.js"><link rel="prefetch" href="/assets/js/34.fb567ebb.js"><link rel="prefetch" href="/assets/js/35.995dd5b1.js"><link rel="prefetch" href="/assets/js/36.ebd63a8c.js"><link rel="prefetch" href="/assets/js/37.8271e61a.js"><link rel="prefetch" href="/assets/js/38.c9c9438e.js"><link rel="prefetch" href="/assets/js/39.517d0e22.js"><link rel="prefetch" href="/assets/js/4.03c84a3c.js"><link rel="prefetch" href="/assets/js/40.0ba08810.js"><link rel="prefetch" href="/assets/js/41.c45513c7.js"><link rel="prefetch" href="/assets/js/42.b42542e4.js"><link rel="prefetch" href="/assets/js/43.5fcfe760.js"><link rel="prefetch" href="/assets/js/44.2165b121.js"><link rel="prefetch" href="/assets/js/45.f011e76a.js"><link rel="prefetch" href="/assets/js/46.b190d321.js"><link rel="prefetch" href="/assets/js/47.30331587.js"><link rel="prefetch" href="/assets/js/48.b43f806e.js"><link rel="prefetch" href="/assets/js/49.206fd543.js"><link rel="prefetch" href="/assets/js/5.dc64067c.js"><link rel="prefetch" href="/assets/js/50.05a55da7.js"><link rel="prefetch" href="/assets/js/51.d88e317e.js"><link rel="prefetch" href="/assets/js/52.d6e778fa.js"><link rel="prefetch" href="/assets/js/53.4bd5b1e2.js"><link rel="prefetch" href="/assets/js/54.a78aaa0b.js"><link rel="prefetch" href="/assets/js/55.5af47d03.js"><link rel="prefetch" href="/assets/js/56.a4a50c46.js"><link rel="prefetch" href="/assets/js/57.3156cbfc.js"><link rel="prefetch" href="/assets/js/58.7cfb4255.js"><link rel="prefetch" href="/assets/js/59.b1ff1dc6.js"><link rel="prefetch" href="/assets/js/6.a365e315.js"><link rel="prefetch" href="/assets/js/60.7afdb568.js"><link rel="prefetch" href="/assets/js/61.a12986d6.js"><link rel="prefetch" href="/assets/js/62.6b5a007d.js"><link rel="prefetch" href="/assets/js/63.0f7fdd37.js"><link rel="prefetch" href="/assets/js/64.992ae837.js"><link rel="prefetch" href="/assets/js/65.63c58056.js"><link rel="prefetch" href="/assets/js/66.e7a6a465.js"><link rel="prefetch" href="/assets/js/67.82e8c6f5.js"><link rel="prefetch" href="/assets/js/68.98939881.js"><link rel="prefetch" href="/assets/js/69.ea3ec205.js"><link rel="prefetch" href="/assets/js/7.bdfa8241.js"><link rel="prefetch" href="/assets/js/70.50155833.js"><link rel="prefetch" href="/assets/js/71.b9f38bfe.js"><link rel="prefetch" href="/assets/js/72.745bb80c.js"><link rel="prefetch" href="/assets/js/73.3b8f8ec8.js"><link rel="prefetch" href="/assets/js/74.1c65e8b3.js"><link rel="prefetch" href="/assets/js/75.2bb6561f.js"><link rel="prefetch" href="/assets/js/76.1e99847e.js"><link rel="prefetch" href="/assets/js/77.4ea27eaa.js"><link rel="prefetch" href="/assets/js/78.ca0a304e.js"><link rel="prefetch" href="/assets/js/79.1e83f7b4.js"><link rel="prefetch" href="/assets/js/80.26785724.js"><link rel="prefetch" href="/assets/js/81.5dca21ef.js"><link rel="prefetch" href="/assets/js/82.28992137.js"><link rel="prefetch" href="/assets/js/83.e585e81c.js"><link rel="prefetch" href="/assets/js/84.0b6772e4.js"><link rel="prefetch" href="/assets/js/85.3df73729.js"><link rel="prefetch" href="/assets/js/86.28abe836.js"><link rel="prefetch" href="/assets/js/87.adc38596.js"><link rel="prefetch" href="/assets/js/88.77eb29c4.js"><link rel="prefetch" href="/assets/js/89.bb094d97.js"><link rel="prefetch" href="/assets/js/9.80b1c449.js"><link rel="prefetch" href="/assets/js/90.324f10ea.js"><link rel="prefetch" href="/assets/js/91.83974a24.js"><link rel="prefetch" href="/assets/js/92.c17b876c.js"><link rel="prefetch" href="/assets/js/93.93d819e9.js"><link rel="prefetch" href="/assets/js/94.c0901e7d.js"><link rel="prefetch" href="/assets/js/95.7c544fc5.js"><link rel="prefetch" href="/assets/js/96.1e4f5c43.js"><link rel="prefetch" href="/assets/js/97.8f8e0dcb.js"><link rel="prefetch" href="/assets/js/98.0c8aaa27.js"><link rel="prefetch" href="/assets/js/99.ec06ce11.js">
    <link rel="stylesheet" href="/assets/css/0.styles.cb5acd6d.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">Apache Ignite技术服务</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  首页
</a></div><div class="nav-item"><a href="/Service.html" class="nav-link">
  服务&amp;报价
</a></div><div class="nav-item"><a href="https://ignite.apache.org/download.cgi" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Ignite软件下载
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="https://www.gridgain.com/resources/download" target="_blank" rel="noopener noreferrer" class="nav-link external">
  GridGain软件试用
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="/doc/java/" class="nav-link">
  文档
</a></div><div class="nav-item"><a href="https://my.oschina.net/liyuj" target="_blank" rel="noopener noreferrer" class="nav-link external">
  博客
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="/confluent/" class="nav-link router-link-active">
  Confluent平台
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Select language" class="dropdown-title"><span class="title">最新版本</span> <span class="arrow down"></span></button> <button type="button" aria-label="Select language" class="mobile-dropdown-title"><span class="title">最新版本</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/confluent/Kafka-ErrorHandlingDeadLetterQueues.html" aria-current="page" class="nav-link router-link-exact-active router-link-active">
  2.10.0
</a></li><li class="dropdown-item"><!----> <a href="/doc/2.9.1/" class="nav-link">
  2.9.1
</a></li><li class="dropdown-item"><!----> <a href="/doc/2.8.0/" class="nav-link">
  2.8.0
</a></li><li class="dropdown-item"><!----> <a href="/doc/2.7.0/" class="nav-link">
  2.7.0
</a></li><li class="dropdown-item"><!----> <a href="/doc/2.6.0/" class="nav-link">
  2.6.0
</a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  首页
</a></div><div class="nav-item"><a href="/Service.html" class="nav-link">
  服务&amp;报价
</a></div><div class="nav-item"><a href="https://ignite.apache.org/download.cgi" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Ignite软件下载
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="https://www.gridgain.com/resources/download" target="_blank" rel="noopener noreferrer" class="nav-link external">
  GridGain软件试用
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="/doc/java/" class="nav-link">
  文档
</a></div><div class="nav-item"><a href="https://my.oschina.net/liyuj" target="_blank" rel="noopener noreferrer" class="nav-link external">
  博客
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="/confluent/" class="nav-link router-link-active">
  Confluent平台
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Select language" class="dropdown-title"><span class="title">最新版本</span> <span class="arrow down"></span></button> <button type="button" aria-label="Select language" class="mobile-dropdown-title"><span class="title">最新版本</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/confluent/Kafka-ErrorHandlingDeadLetterQueues.html" aria-current="page" class="nav-link router-link-exact-active router-link-active">
  2.10.0
</a></li><li class="dropdown-item"><!----> <a href="/doc/2.9.1/" class="nav-link">
  2.9.1
</a></li><li class="dropdown-item"><!----> <a href="/doc/2.8.0/" class="nav-link">
  2.8.0
</a></li><li class="dropdown-item"><!----> <a href="/doc/2.7.0/" class="nav-link">
  2.7.0
</a></li><li class="dropdown-item"><!----> <a href="/doc/2.6.0/" class="nav-link">
  2.6.0
</a></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><a href="/confluent/" aria-current="page" class="sidebar-link">Kafka Connect深度解读之JDBC源连接器</a></li><li><a href="/confluent/Kafka-ConvertersSerialization.html" class="sidebar-link">Kafka Connect深度解读之转换器和序列化</a></li><li><a href="/confluent/Kafka-ErrorHandlingDeadLetterQueues.html" aria-current="page" class="active sidebar-link">Kafka Connect深度解读之错误处理和死信队列</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/confluent/Kafka-ErrorHandlingDeadLetterQueues.html#失败后立即停止" class="sidebar-link">失败后立即停止</a></li><li class="sidebar-sub-header"><a href="/confluent/Kafka-ErrorHandlingDeadLetterQueues.html#静默忽略无效的消息" class="sidebar-link">静默忽略无效的消息</a></li><li class="sidebar-sub-header"><a href="/confluent/Kafka-ErrorHandlingDeadLetterQueues.html#是否可以感知数据的丢失" class="sidebar-link">是否可以感知数据的丢失？</a></li><li class="sidebar-sub-header"><a href="/confluent/Kafka-ErrorHandlingDeadLetterQueues.html#将消息路由到死信队列" class="sidebar-link">将消息路由到死信队列</a></li><li class="sidebar-sub-header"><a href="/confluent/Kafka-ErrorHandlingDeadLetterQueues.html#记录消息的失败原因-消息头" class="sidebar-link">记录消息的失败原因：消息头</a></li><li class="sidebar-sub-header"><a href="/confluent/Kafka-ErrorHandlingDeadLetterQueues.html#记录消息的失败原因-日志" class="sidebar-link">记录消息的失败原因：日志</a></li><li class="sidebar-sub-header"><a href="/confluent/Kafka-ErrorHandlingDeadLetterQueues.html#处理死信队列的消息" class="sidebar-link">处理死信队列的消息</a></li><li class="sidebar-sub-header"><a href="/confluent/Kafka-ErrorHandlingDeadLetterQueues.html#通过ksql监控死信队列" class="sidebar-link">通过KSQL监控死信队列</a></li><li class="sidebar-sub-header"><a href="/confluent/Kafka-ErrorHandlingDeadLetterQueues.html#kafka-connect哪里没有提供错误处理" class="sidebar-link">Kafka Connect哪里没有提供错误处理？</a></li><li class="sidebar-sub-header"><a href="/confluent/Kafka-ErrorHandlingDeadLetterQueues.html#错误处理配置流程" class="sidebar-link">错误处理配置流程</a></li><li class="sidebar-sub-header"><a href="/confluent/Kafka-ErrorHandlingDeadLetterQueues.html#总结" class="sidebar-link">总结</a></li></ul></li><li><a href="/confluent/Kafka-CreateDynamicConnectors.html" class="sidebar-link">使用Connect API创建自定义Kafka Connect</a></li><li><a href="/confluent/Kafka-SingleMessageTransformation.html" class="sidebar-link">Kafka Connect深度解读之单消息转换</a></li><li><a href="/confluent/Kafka-ConnectImprovementsIn-2-3.html" class="sidebar-link">Kafka Connect之在2.3版本中的改进</a></li><li><a href="/confluent/Kafka-FastestMessagingSystem.html" class="sidebar-link">Apache Kafka、Apache Pulsar和RabbitMQ性能测试对比</a></li><li><a href="/confluent/SecureKafkaDeploymentBestPractices.html" class="sidebar-link">保护Kafka环境的最佳实践</a></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="kafka-connect深度解读之错误处理和死信队列"><a href="#kafka-connect深度解读之错误处理和死信队列" class="header-anchor">#</a> Kafka Connect深度解读之错误处理和死信队列</h1> <p>Kafka Connect是Kafka的一部分，是在Kafka和其它技术之间构建流式管道的一个强有力的框架。它可用于将数据从多个地方（包括数据库、消息队列和文本文件）流式注入到Kafka，以及从Kafka将数据流式传输到目标端（如文档存储、NoSQL、数据库、对象存储等）中。</p> <p>现实世界并不完美，出错是难免的，因此在出错时Kafka的管道能尽可能优雅地处理是最好的。一个常见的场景是获取与特定序列化格式不匹配的主题的消息（比如预期为Avro时实际为JSON，反之亦然）。自从Kafka 2.0版本发布以来，Kafka Connect包含了错误处理选项，即将消息路由到<em>死信队列</em>的功能，这是构建数据管道的常用技术。</p> <p>在本文中将介绍几种处理问题的常见模式，并说明如何实现。</p> <h2 id="失败后立即停止"><a href="#失败后立即停止" class="header-anchor">#</a> 失败后立即停止</h2> <p>有时可能希望在发生错误时立即停止处理，可能遇到质量差的数据是由于上游的原因导致的，必须由上游来解决，继续尝试处理其它的消息已经没有意义。</p> <p><img src="https://www.confluent.io/wp-content/uploads/Source_Topic_Messages_Kafka_Connect_Sink_Messages-e1552329568691.png" alt=""></p> <p>这是Kafka Connect的默认行为，也可以使用下面的配置项显式地指定：</p> <div class="language-properties extra-class"><pre class="language-properties"><code><span class="token attr-name">errors.tolerance</span> <span class="token punctuation">=</span> <span class="token attr-value">none</span>
</code></pre></div><p>在本示例中，该连接器配置为从主题中读取JSON格式数据，然后将其写入纯文本文件。注意这里为了演示使用的是<code>FileStreamSinkConnector</code>连接器，不建议在生产中使用。</p> <div class="language- extra-class"><pre class="language-text"><code>curl -X POST http://localhost:8083/connectors -H &quot;Content-Type: application/json&quot; -d '{
        &quot;name&quot;: &quot;file_sink_01&quot;,
        &quot;config&quot;: {
                &quot;connector.class&quot;: &quot;org.apache.kafka.connect.file.FileStreamSinkConnector&quot;,
                &quot;topics&quot;:&quot;test_topic_json&quot;,
                &quot;value.converter&quot;:&quot;org.apache.kafka.connect.json.JsonConverter&quot;,
                &quot;value.converter.schemas.enable&quot;: false,
                &quot;key.converter&quot;:&quot;org.apache.kafka.connect.json.JsonConverter&quot;,
                &quot;key.converter.schemas.enable&quot;: false,
                &quot;file&quot;:&quot;/data/file_sink_01.txt&quot;
                }
        }'
</code></pre></div><p>主题中的某些JSON格式消息是无效的，连接器会立即终止，进入以下的<code>FAILED</code>状态：</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token function">curl</span> -s <span class="token string">&quot;http://localhost:8083/connectors/file_sink_01/status&quot;</span><span class="token operator">|</span> <span class="token punctuation">\</span>
    jq -c -M <span class="token string">'[.name,.tasks[].state]'</span>
<span class="token punctuation">[</span><span class="token string">&quot;file_sink_01&quot;</span>,<span class="token string">&quot;FAILED&quot;</span><span class="token punctuation">]</span>
</code></pre></div><p>查看Kafka Connect工作节点的日志，可以看到错误已经记录并且任务已经终止：</p> <div class="language- extra-class"><pre class="language-text"><code>org.apache.kafka.connect.errors.ConnectException: Tolerance exceeded in error handler
 at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:178)
…
Caused by: org.apache.kafka.connect.errors.DataException: Converting byte[] to Kafka Connect data failed due to serialization error:
 at org.apache.kafka.connect.json.JsonConverter.toConnectData(JsonConverter.java:334)
…
Caused by: org.apache.kafka.common.errors.SerializationException: com.fasterxml.jackson.core.JsonParseException: Unexpected character ('b' (code 98)): was expecting double-quote to start field name
 at [Source: (byte[])&quot;{brokenjson-:&quot;bar 1&quot;}&quot;; line: 1, column: 3]
</code></pre></div><p>要修复管道，需要解决源主题上的消息问题。除非事先指定，Kafka Connect是不会简单地“跳过”无效消息的。如果是配置错误（例如指定了错误的序列化转换器），那最好了，改正之后重新启动连接器即可。不过如果确实是该主题的无效消息，那么需要找到一种方式，即不要阻止所有其它有效消息的处理。</p> <h2 id="静默忽略无效的消息"><a href="#静默忽略无效的消息" class="header-anchor">#</a> 静默忽略无效的消息</h2> <p>如果只是希望处理一直持续下去：</p> <div class="language-properties extra-class"><pre class="language-properties"><code><span class="token attr-name">errors.tolerance</span> <span class="token punctuation">=</span> <span class="token attr-value">all</span>
</code></pre></div><p><img src="https://www.confluent.io/wp-content/uploads/Source_Topic_Messages_Kafka_Connect_Sink_Messages_v2-e1552330256955.png" alt=""></p> <p>在实际中大概如下：</p> <div class="language- extra-class"><pre class="language-text"><code>curl -X POST http://localhost:8083/connectors -H &quot;Content-Type: application/json&quot; -d '{
        &quot;name&quot;: &quot;file_sink_05&quot;,
        &quot;config&quot;: {
                &quot;connector.class&quot;: &quot;org.apache.kafka.connect.file.FileStreamSinkConnector&quot;,
                &quot;topics&quot;:&quot;test_topic_json&quot;,
                &quot;value.converter&quot;:&quot;org.apache.kafka.connect.json.JsonConverter&quot;,
                &quot;value.converter.schemas.enable&quot;: false,
                &quot;key.converter&quot;:&quot;org.apache.kafka.connect.json.JsonConverter&quot;,
                &quot;key.converter.schemas.enable&quot;: false,
                &quot;file&quot;:&quot;/data/file_sink_05.txt&quot;,
                &quot;errors.tolerance&quot;: &quot;all&quot;
                }
        }'
</code></pre></div><p>启动连接器之后（还是原来的源主题，其中既有有效的，也有无效的消息），就可以持续地运行：</p> <div class="language- extra-class"><pre class="language-text"><code>$ curl -s &quot;http://localhost:8083/connectors/file_sink_05/status&quot;| \
    jq -c -M '[.name,.tasks[].state]'
[&quot;file_sink_05&quot;,&quot;RUNNING&quot;]
</code></pre></div><p>这时即使连接器读取的源主题上有无效的消息，也不会有错误写入Kafka Connect工作节点的输出，而有效的消息会按照预期写入输出文件：</p> <div class="language- extra-class"><pre class="language-text"><code>$ head data/file_sink_05.txt
{foo=bar 1}
{foo=bar 2}
{foo=bar 3}
…
</code></pre></div><h2 id="是否可以感知数据的丢失"><a href="#是否可以感知数据的丢失" class="header-anchor">#</a> 是否可以感知数据的丢失？</h2> <p>配置了<code>errors.tolerance = all</code>之后，Kafka Connect就会忽略掉无效的消息，并且默认也不会记录被丢弃的消息。如果确认配置<code>errors.tolerance = all</code>，那么就需要仔细考虑是否以及如何知道实际上发生的消息丢失。在实践中这意味着基于可用指标的监控/报警，和/或失败消息的记录。</p> <p>确定是否有消息被丢弃的最简单方法，是将源主题上的消息数与写入目标端的数量进行对比：</p> <div class="language- extra-class"><pre class="language-text"><code>$ kafkacat -b localhost:9092 -t test_topic_json -o beginning -C -e -q -X enable.partition.eof=true | wc -l
     150

$ wc -l data/file_sink_05.txt
     100 data/file_sink_05.txt
</code></pre></div><p>这个做法虽然不是很优雅，但是确实能看出发生了消息的丢失，并且因为日志中没有记录，所以用户仍然对此一无所知。</p> <p>一个更加可靠的办法是，使用<a href="https://kafka.apache.org/documentation/#connect_monitoring" target="_self" rel="noopener noreferrer">JMX指标</a>来主动监控和报警错误消息率：</p> <p><img src="https://www.confluent.io/wp-content/uploads/Kafka_Connect_Totals-e1552339993226.png" alt=""></p> <p>这时可以看到发生了错误，但是并不知道那些消息发生了错误，不过这是用户想要的。其实即使之后这些被丢弃的消息被写入了<code>/dev/null</code>，实际上也是可以知道的，这也正是死信队列概念出现的点。</p> <h2 id="将消息路由到死信队列"><a href="#将消息路由到死信队列" class="header-anchor">#</a> 将消息路由到死信队列</h2> <p>Kafka Connect可以配置为将无法处理的消息（例如上面提到的反序列化错误）发送到一个单独的Kafka主题，即死信队列。有效消息会正常处理，管道也会继续运行。然后可以从死信队列中检查无效消息，并根据需要忽略或修复并重新处理。</p> <p><img src="https://www.confluent.io/wp-content/uploads/DLQ_Source_Topic_Messages_Kafka_Connect_Sink_Messages-e1552339900964.png" alt=""></p> <p>进行如下的配置可以启用死信队列：</p> <div class="language-properties extra-class"><pre class="language-properties"><code><span class="token attr-name">errors.tolerance</span> <span class="token punctuation">=</span> <span class="token attr-value">all</span>
<span class="token attr-name">errors.deadletterqueue.topic.name</span> <span class="token punctuation">=</span><span class="token attr-value"> </span>
</code></pre></div><p>如果运行于单节点Kafka集群，还需要配置<code>errors.deadletterqueue.topic.replication.factor = 1</code>，其默认值为3。</p> <p>具有此配置的连接器配置示例大致如下：</p> <div class="language- extra-class"><pre class="language-text"><code>curl -X POST http://localhost:8083/connectors -H &quot;Content-Type: application/json&quot; -d '{
        &quot;name&quot;: &quot;file_sink_02&quot;,
        &quot;config&quot;: {
                &quot;connector.class&quot;: &quot;org.apache.kafka.connect.file.FileStreamSinkConnector&quot;,
                &quot;topics&quot;:&quot;test_topic_json&quot;,
                &quot;value.converter&quot;:&quot;org.apache.kafka.connect.json.JsonConverter&quot;,
                &quot;value.converter.schemas.enable&quot;: false,
                &quot;key.converter&quot;:&quot;org.apache.kafka.connect.json.JsonConverter&quot;,
                &quot;key.converter.schemas.enable&quot;: false,
                &quot;file&quot;: &quot;/data/file_sink_02.txt&quot;,
                &quot;errors.tolerance&quot;: &quot;all&quot;,
                &quot;errors.deadletterqueue.topic.name&quot;:&quot;dlq_file_sink_02&quot;,
                &quot;errors.deadletterqueue.topic.replication.factor&quot;: 1
                }
        }'
</code></pre></div><p>使用和之前相同的源主题，然后处理混合有有效和无效的JSON数据，会看到新的连接器可以稳定运行：</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token function">curl</span> -s <span class="token string">&quot;http://localhost:8083/connectors/file_sink_02/status&quot;</span><span class="token operator">|</span> <span class="token punctuation">\</span>
    jq -c -M <span class="token string">'[.name,.tasks[].state]'</span>
<span class="token punctuation">[</span><span class="token string">&quot;file_sink_02&quot;</span>,<span class="token string">&quot;RUNNING&quot;</span><span class="token punctuation">]</span>
</code></pre></div><p>源主题中的有效记录将写入目标文件：</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token function">head</span> data/file_sink_02.txt
<span class="token punctuation">{</span>foo<span class="token operator">=</span>bar <span class="token number">1</span><span class="token punctuation">}</span>
<span class="token punctuation">{</span>foo<span class="token operator">=</span>bar <span class="token number">2</span><span class="token punctuation">}</span>
<span class="token punctuation">{</span>foo<span class="token operator">=</span>bar <span class="token number">3</span><span class="token punctuation">}</span>
<span class="token punctuation">[</span>…<span class="token punctuation">]</span>
</code></pre></div><p>这样管道可以继续正常运行，并且还有了死信队列主题中的数据，这可以从指标数据中看出：</p> <p><img src="https://www.confluent.io/wp-content/uploads/Kafka_Connect_Graph-e1552408650942.png" alt=""></p> <p>检查主题本身也可以看出来：</p> <div class="language- extra-class"><pre class="language-text"><code>ksql&gt; LIST TOPICS;

 Kafka Topic            | Registered | Partitions | Partition Replicas | Consumers | ConsumerGroups
---------------------------------------------------------------------------------------------------
 dlq_file_sink_02       | false      | 1          | 1                  | 0         | 0
 test_topic_json        | false      | 1          | 1                  | 1         | 1
---------------------------------------------------------------------------------------------------

ksql&gt; PRINT 'dlq_file_sink_02' FROM BEGINNING;
Format:STRING
1/24/19 5:16:03 PM UTC , NULL , {foo:&quot;bar 1&quot;}
1/24/19 5:16:03 PM UTC , NULL , {foo:&quot;bar 2&quot;}
1/24/19 5:16:03 PM UTC , NULL , {foo:&quot;bar 3&quot;}
…
</code></pre></div><p>从输出中可以看出，消息的时间戳为（<code>1/24/19 5:16:03 PM UTC</code>），键为（<code>NULL</code>），然后为值。这时可以看到值是无效的JSON格式<code>{foo:&quot;bar 1&quot;}</code>（<code>foo</code>也应加上引号），因此JsonConverter在处理时会抛出异常，因此最终会输出到死信主题。</p> <p>但是只有看到消息才能知道它是无效的JSON，即便如此，也只能假设消息被拒绝的原因，要确定Kafka Connect将消息视为无效的实际原因，有两个方法：</p> <ul><li>死信队列的消息头；</li> <li>Kafka Connect的工作节点日志。</li></ul> <p>下面会分别介绍。</p> <h2 id="记录消息的失败原因-消息头"><a href="#记录消息的失败原因-消息头" class="header-anchor">#</a> 记录消息的失败原因：消息头</h2> <p>消息头是使用Kafka消息的键、值和时间戳存储的附加元数据，是在Kafka 0.11版本中引入的。Kafka Connect可以将有关消息拒绝原因的信息写入消息本身的消息头中。这个做法比写入日志文件更好，因为它将原因直接与消息联系起来。</p> <p>配置如下的参数，可以在死信队列的消息头中包含拒绝原因：</p> <div class="language-properties extra-class"><pre class="language-properties"><code><span class="token attr-name">errors.deadletterqueue.context.headers.enable</span> <span class="token punctuation">=</span> <span class="token attr-value">true</span>
</code></pre></div><p>配置示例大致如下：</p> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token function">curl</span> -X POST http://localhost:8083/connectors -H <span class="token string">&quot;Content-Type: application/json&quot;</span> -d <span class="token string">'{
        &quot;name&quot;: &quot;file_sink_03&quot;,
        &quot;config&quot;: {
                &quot;connector.class&quot;: &quot;org.apache.kafka.connect.file.FileStreamSinkConnector&quot;,
                &quot;topics&quot;:&quot;test_topic_json&quot;,
                &quot;value.converter&quot;:&quot;org.apache.kafka.connect.json.JsonConverter&quot;,
                &quot;value.converter.schemas.enable&quot;: false,
                &quot;key.converter&quot;:&quot;org.apache.kafka.connect.json.JsonConverter&quot;,
                &quot;key.converter.schemas.enable&quot;: false,
                &quot;file&quot;: &quot;/data/file_sink_03.txt&quot;,
                &quot;errors.tolerance&quot;: &quot;all&quot;,
                &quot;errors.deadletterqueue.topic.name&quot;:&quot;dlq_file_sink_03&quot;,
                &quot;errors.deadletterqueue.topic.replication.factor&quot;: 1,
                &quot;errors.deadletterqueue.context.headers.enable&quot;:true
                }
        }'</span>
</code></pre></div><p>和之前一致，连接器可以正常运行（因为配置了<code>errors.tolerance=all</code>）。</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token function">curl</span> -s <span class="token string">&quot;http://localhost:8083/connectors/file_sink_03/status&quot;</span><span class="token operator">|</span> <span class="token punctuation">\</span>
    jq -c -M <span class="token string">'[.name,.tasks[].state]'</span>
<span class="token punctuation">[</span><span class="token string">&quot;file_sink_03&quot;</span>,<span class="token string">&quot;RUNNING&quot;</span><span class="token punctuation">]</span>
</code></pre></div><p>源主题中的有效消息会正常写入目标文件：</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token function">head</span> data/file_sink_03.txt
<span class="token punctuation">{</span>foo<span class="token operator">=</span>bar <span class="token number">1</span><span class="token punctuation">}</span>
<span class="token punctuation">{</span>foo<span class="token operator">=</span>bar <span class="token number">2</span><span class="token punctuation">}</span>
<span class="token punctuation">{</span>foo<span class="token operator">=</span>bar <span class="token number">3</span><span class="token punctuation">}</span>
<span class="token punctuation">[</span>…<span class="token punctuation">]</span>
</code></pre></div><p>可以使用任何消费者工具来检查死信队列上的消息（之前使用了KSQL），不过这里会使用kafkacat，然后马上就会看到原因，最简单的操作大致如下：</p> <div class="language-bash extra-class"><pre class="language-bash"><code>kafkacat -b localhost:9092 -t dlq_file_sink_03
% Auto-selecting Consumer mode <span class="token punctuation">(</span>use -P or -C to override<span class="token punctuation">)</span>
<span class="token punctuation">{</span>foo:<span class="token string">&quot;bar 1&quot;</span><span class="token punctuation">}</span>
<span class="token punctuation">{</span>foo:<span class="token string">&quot;bar 2&quot;</span><span class="token punctuation">}</span>
…
</code></pre></div><p>不过kafkacat有更强大的功能，可以看到比消息本身更多的信息：</p> <div class="language-bash extra-class"><pre class="language-bash"><code>kafkacat -b localhost:9092 -t dlq_file_sink_03 -C -o-1 -c1 <span class="token punctuation">\</span>
  -f <span class="token string">'<span class="token entity" title="\n">\n</span>Key (%K bytes): %k
  Value (%S bytes): %s
  Timestamp: %T
  Partition: %p
  Offset: %o
  Headers: %h<span class="token entity" title="\n">\n</span>'</span>
</code></pre></div><p>这个命令将获取最后一条消息（<code>-o-1</code>，针对偏移量，使用最后一条消息），只读取一条消息（<code>-c1</code>），并且通过<code>-f</code>参数对其进行格式化，以更易于理解：</p> <div class="language- extra-class"><pre class="language-text"><code>Key (-1 bytes):
  Value (13 bytes): {foo:&quot;bar 5&quot;}
  Timestamp: 1548350164096
  Partition: 0
  Offset: 34
  Headers: __connect.errors.topic=test_topic_json,__connect.errors.partition=0,__connect.errors.offset=94,__connect.errors.connector.name=file_sink_03,__connect.errors.task.id=0,__connect.errors.stage=VALU
E_CONVERTER,__connect.errors.class.name=org.apache.kafka.connect.json.JsonConverter,__connect.errors.exception.class.name=org.apache.kafka.connect.errors.DataException,__connect.errors.exception.message=Co
nverting byte[] to Kafka Connect data failed due to serialization error: ,__connect.errors.exception.stacktrace=org.apache.kafka.connect.errors.DataException: Converting byte[] to Kafka Connect data failed
 due to serialization error:
[…]
</code></pre></div><p>也可以只显示消息头，并使用一些简单的技巧将其拆分，这样可以更清楚地看到该问题的更多信息：</p> <div class="language- extra-class"><pre class="language-text"><code>$ kafkacat -b localhost:9092 -t dlq_file_sink_03 -C -o-1 -c1 -f '%h'|tr ',' '\n'
__connect.errors.topic=test_topic_json
__connect.errors.partition=0
__connect.errors.offset=94
__connect.errors.connector.name=file_sink_03
__connect.errors.task.id=0
__connect.errors.stage=VALUE_CONVERTER
__connect.errors.class.name=org.apache.kafka.connect.json.JsonConverter
__connect.errors.exception.class.name=org.apache.kafka.connect.errors.DataException
__connect.errors.exception.message=Converting byte[] to Kafka Connect data failed due to serialization error:
</code></pre></div><p>Kafka Connect处理的每条消息都来自源主题和该主题中的特定点（偏移量），消息头已经准确地说明了这一点。因此可以使用它来回到原始主题并在需要时检查原始消息，由于死信队列已经有一个消息的副本，这个检查更像是一个保险的做法。</p> <p>根据从上面的消息头中获取的详细信息，可以再检查一下源消息：</p> <div class="language- extra-class"><pre class="language-text"><code>__connect.errors.topic=test_topic_json
__connect.errors.offset=94
</code></pre></div><p>将这些值分别插入到kafkacat的代表主题和偏移的<code>-t</code>和<code>-o</code>参数中，可以得到：</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ kafkacat -b localhost:9092 -C <span class="token punctuation">\</span>
  -t test_topic_json -o94 <span class="token punctuation">\</span>
  -f <span class="token string">'<span class="token entity" title="\n">\n</span>Key (%K bytes): %k
  Value (%S bytes): %s
  Timestamp: %T
  Partition: %p
  Offset: %o
  Topic: %t<span class="token entity" title="\n">\n</span>'</span>
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>Key (-1 bytes):
  Value (13 bytes): {foo:&quot;bar 5&quot;}
  Timestamp: 1548350164096
  Partition: 0
  Offset: 94
  Topic: test_topic_json
</code></pre></div><p>与死信队列中的上述消息相比，可以看到完全相同，甚至包括时间戳，唯一的区别是主题、偏移量和消息头。</p> <h2 id="记录消息的失败原因-日志"><a href="#记录消息的失败原因-日志" class="header-anchor">#</a> 记录消息的失败原因：日志</h2> <p>记录消息的拒绝原因的第二个选项是将其写入日志。根据安装方式不同，Kafka Connect会将其写入标准输出或日志文件。无论哪种方式都会为每个失败的消息生成一堆详细输出。进行如下配置可启用此功能：</p> <div class="language-properties extra-class"><pre class="language-properties"><code><span class="token attr-name">errors.log.enable</span> <span class="token punctuation">=</span> <span class="token attr-value">true</span>
</code></pre></div><p>通过配置<code>errors.log.include.messages = true</code>，还可以在输出中包含有关消息本身的元数据。此元数据中包括一些和上面提到的消息头中一样的项目，包括源消息的主题和偏移量。注意它不包括消息键或值本身。</p> <p>这时的连接器配置如下：</p> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token function">curl</span> -X POST http://localhost:8083/connectors -H <span class="token string">&quot;Content-Type: application/json&quot;</span> -d <span class="token string">'{
        &quot;name&quot;: &quot;file_sink_04&quot;,
        &quot;config&quot;: {
                &quot;connector.class&quot;: &quot;org.apache.kafka.connect.file.FileStreamSinkConnector&quot;,
                &quot;topics&quot;:&quot;test_topic_json&quot;,
                &quot;value.converter&quot;:&quot;org.apache.kafka.connect.json.JsonConverter&quot;,
                &quot;value.converter.schemas.enable&quot;: false,
                &quot;key.converter&quot;:&quot;org.apache.kafka.connect.json.JsonConverter&quot;,
                &quot;key.converter.schemas.enable&quot;: false,
                &quot;file&quot;: &quot;/data/file_sink_04.txt&quot;,
                &quot;errors.tolerance&quot;: &quot;all&quot;,
                &quot;errors.log.enable&quot;:true,
                &quot;errors.log.include.messages&quot;:true
                }
        }'</span>
</code></pre></div><p>连接器是可以成功运行的：</p> <div class="language-bash extra-class"><pre class="language-bash"><code>$ <span class="token function">curl</span> -s <span class="token string">&quot;http://localhost:8083/connectors/file_sink_04/status&quot;</span><span class="token operator">|</span> <span class="token punctuation">\</span>
    jq -c -M <span class="token string">'[.name,.tasks[].state]'</span>
<span class="token punctuation">[</span><span class="token string">&quot;file_sink_04&quot;</span>,<span class="token string">&quot;RUNNING&quot;</span><span class="token punctuation">]</span>
Valid records from the <span class="token builtin class-name">source</span> topic get written to the target file:
$ <span class="token function">head</span> data/file_sink_04.txt
<span class="token punctuation">{</span>foo<span class="token operator">=</span>bar <span class="token number">1</span><span class="token punctuation">}</span>
<span class="token punctuation">{</span>foo<span class="token operator">=</span>bar <span class="token number">2</span><span class="token punctuation">}</span>
<span class="token punctuation">{</span>foo<span class="token operator">=</span>bar <span class="token number">3</span><span class="token punctuation">}</span>
<span class="token punctuation">[</span>…<span class="token punctuation">]</span>
</code></pre></div><p>这时去看Kafka Connect的工作节点日志，会发现每个失败的消息都有错误记录：</p> <div class="language- extra-class"><pre class="language-text"><code>ERROR Error encountered in task file_sink_04-0. Executing stage 'VALUE_CONVERTER' with class 'org.apache.kafka.connect.json.JsonConverter', where consumed record is {topic='test_topic_json', partition=0, offset=94, timestamp=1548350164096, timestampType=CreateTime}. (org.apache.kafka.connect.runtime.errors.LogReporter)
org.apache.kafka.connect.errors.DataException: Converting byte[] to Kafka Connect data failed due to serialization error:
 at org.apache.kafka.connect.json.JsonConverter.toConnectData(JsonConverter.java:334)
[…]
Caused by: org.apache.kafka.common.errors.SerializationException: com.fasterxml.jackson.core.JsonParseException: Unexpected character ('f' (code 102)): was expecting double-quote to start field name
 at [Source: (byte[])&quot;{foo:&quot;bar 5&quot;}&quot;; line: 1, column: 3]
</code></pre></div><p>可以看到错误本身，还有就是和错误有关的信息：</p> <div class="language- extra-class"><pre class="language-text"><code>{topic='test_topic_json', partition=0, offset=94, timestamp=1548350164096, timestampType=CreateTime}
</code></pre></div><p>如上所示，可以在kafkacat等工具中使用该主题和偏移量来检查源主题上的消息。根据抛出的异常也可能会看到记录的源消息：</p> <div class="language- extra-class"><pre class="language-text"><code>Caused by: org.apache.kafka.common.errors.SerializationException:
…
at [Source: (byte[])&quot;{foo:&quot;bar 5&quot;}&quot;; line: 1, column: 3]
</code></pre></div><h2 id="处理死信队列的消息"><a href="#处理死信队列的消息" class="header-anchor">#</a> 处理死信队列的消息</h2> <p>虽然设置了一个死信队列，但是如何处理那些“死信”呢？因为它只是一个Kafka主题，所以可以像使用任何其它主题一样使用标准的Kafka工具。上面已经看到了，比如可以使用kafkacat来检查消息头，并且对于消息的内容及其元数据的一般检查kafkacat也可以做。当然根据被拒绝的原因，也可以选择对消息进行重播。</p> <p>一个场景是连接器正在使用Avro转换器，但是主题上的却是JSON格式消息（因此被写入死信队列）。可能由于遗留原因JSON和Avro格式的生产者都在写入源主题，这个问题得解决，但是目前只需要将管道流中的数据写入接收器即可。</p> <p>首先，从初始的接收器读取源主题开始，使用Avro反序列化并路由到死信队列：</p> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token function">curl</span> -X POST http://localhost:8083/connectors -H <span class="token string">&quot;Content-Type: application/json&quot;</span> -d <span class="token string">'{
        &quot;name&quot;: &quot;file_sink_06__01-avro&quot;,
        &quot;config&quot;: {
                &quot;connector.class&quot;: &quot;org.apache.kafka.connect.file.FileStreamSinkConnector&quot;,
                &quot;topics&quot;:&quot;test_topic_avro&quot;,
                &quot;file&quot;:&quot;/data/file_sink_06.txt&quot;,
                &quot;key.converter&quot;: &quot;io.confluent.connect.avro.AvroConverter&quot;,
                &quot;key.converter.schema.registry.url&quot;: &quot;http://schema-registry:8081&quot;,
                &quot;value.converter&quot;: &quot;io.confluent.connect.avro.AvroConverter&quot;,
                &quot;value.converter.schema.registry.url&quot;: &quot;http://schema-registry:8081&quot;,
                &quot;errors.tolerance&quot;:&quot;all&quot;,
                &quot;errors.deadletterqueue.topic.name&quot;:&quot;dlq_file_sink_06__01&quot;,
                &quot;errors.deadletterqueue.topic.replication.factor&quot;:1,
                &quot;errors.deadletterqueue.context.headers.enable&quot;:true,
                &quot;errors.retry.delay.max.ms&quot;: 60000,
                &quot;errors.retry.timeout&quot;: 300000
                }
        }'</span>
</code></pre></div><p>另外再创建第二个接收器，将第一个接收器的死信队列作为源主题，并尝试将记录反序列化为JSON，在这里要更改的是<code>value.converter</code>、<code>key.converter</code>、源主题名和死信队列名（如果此连接器需要将任何消息路由到死信队列，要避免递归）。</p> <p><img src="https://www.confluent.io/wp-content/uploads/Create_Second_Sink-e1552340041115.png" alt=""></p> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token function">curl</span> -X POST http://localhost:8083/connectors -H <span class="token string">&quot;Content-Type: application/json&quot;</span> -d <span class="token string">'{
        &quot;name&quot;: &quot;file_sink_06__02-json&quot;,
        &quot;config&quot;: {
                &quot;connector.class&quot;: &quot;org.apache.kafka.connect.file.FileStreamSinkConnector&quot;,
                &quot;topics&quot;:&quot;dlq_file_sink_06__01&quot;,
                &quot;file&quot;:&quot;/data/file_sink_06.txt&quot;,
                &quot;value.converter&quot;:&quot;org.apache.kafka.connect.json.JsonConverter&quot;,
                &quot;value.converter.schemas.enable&quot;: false,
                &quot;key.converter&quot;:&quot;org.apache.kafka.connect.json.JsonConverter&quot;,
                &quot;key.converter.schemas.enable&quot;: false,
                &quot;errors.tolerance&quot;:&quot;all&quot;,
                &quot;errors.deadletterqueue.topic.name&quot;:&quot;dlq_file_sink_06__02&quot;,
                &quot;errors.deadletterqueue.topic.replication.factor&quot;:1,
                &quot;errors.deadletterqueue.context.headers.enable&quot;:true,
                &quot;errors.retry.delay.max.ms&quot;: 60000,
                &quot;errors.retry.timeout&quot;: 300000
                }
        }'</span>
</code></pre></div><p>现在可以验证一下。</p> <p>首先，源主题收到20条Avro消息，之后可以看到20条消息被读取并被原始Avro接收器接收：</p> <p><img src="https://www.confluent.io/wp-content/uploads/Source_Records_Read_Avro_Sink_Records_Written-e1552335642875.png" alt=""></p> <p>然后发送8条JSON消息，这时8条消息被发送到死信队列，然后被JSON接收器接收：</p> <p><img src="https://www.confluent.io/wp-content/uploads/JSON_Records_Messages_DLQ_JSON_Sink-e1552335802462.png" alt=""></p> <p>现在再发送5条格式错误的JSON消息，之后可以看到两者都有失败的消息，有2点可以确认：</p> <ol><li>从Avro接收器发送到死信队列的消息数与成功发送的JSON消息数之间有差异；</li> <li>消息被发送到JSON接收器的死信队列。</li></ol> <p><img src="https://www.confluent.io/wp-content/uploads/Records_Requests-e1552335946185.png" alt=""></p> <h2 id="通过ksql监控死信队列"><a href="#通过ksql监控死信队列" class="header-anchor">#</a> 通过KSQL监控死信队列</h2> <p>除了使用JMX监控死信队列之外，还可以利用KSQL的聚合能力编写一个简单的流应用来监控消息写入队列的速率：</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 为每个死信队列主题注册流。</span>
<span class="token keyword">CREATE</span> STREAM dlq_file_sink_06__01（MSG <span class="token keyword">VARCHAR</span>）<span class="token keyword">WITH</span>（KAFKA_TOPIC <span class="token operator">=</span><span class="token string">'dlq_file_sink_06__01'</span>，VALUE_FORMAT <span class="token operator">=</span><span class="token string">'DELIMITED'</span>）<span class="token punctuation">;</span>
<span class="token keyword">CREATE</span> STREAM dlq_file_sink_06__02（MSG <span class="token keyword">VARCHAR</span>）<span class="token keyword">WITH</span>（KAFKA_TOPIC <span class="token operator">=</span><span class="token string">'dlq_file_sink_06__02'</span>，VALUE_FORMAT <span class="token operator">=</span><span class="token string">'DELIMITED'</span>）<span class="token punctuation">;</span>

<span class="token comment">-- 从主题的开头消费数据</span>
<span class="token keyword">SET</span> <span class="token string">'auto.offset.reset'</span> <span class="token operator">=</span> <span class="token string">'earliest'</span><span class="token punctuation">;</span>

<span class="token comment">-- 使用其它列创建监控流，可用于后续聚合查询</span>
<span class="token keyword">CREATE</span> STREAM DLQ_MONITOR <span class="token keyword">WITH</span> <span class="token punctuation">(</span>VALUE_FORMAT<span class="token operator">=</span><span class="token string">'AVRO'</span><span class="token punctuation">)</span> <span class="token keyword">AS</span> \
  <span class="token keyword">SELECT</span> <span class="token string">'dlq_file_sink_06__01'</span> <span class="token keyword">AS</span> SINK_NAME<span class="token punctuation">,</span> \
         <span class="token string">'Records: '</span> <span class="token keyword">AS</span> GROUP_COL<span class="token punctuation">,</span> \
         MSG \
    <span class="token keyword">FROM</span> dlq_file_sink_06__01<span class="token punctuation">;</span>

<span class="token comment">-- 使用来自第二个死信队列的消息注入相同的监控流</span>
<span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> DLQ_MONITOR \
  <span class="token keyword">SELECT</span> <span class="token string">'dlq_file_sink_06__02'</span> <span class="token keyword">AS</span> SINK_NAME<span class="token punctuation">,</span> \
         <span class="token string">'Records: '</span> <span class="token keyword">AS</span> GROUP_COL<span class="token punctuation">,</span> \
         MSG \
    <span class="token keyword">FROM</span> dlq_file_sink_06__02<span class="token punctuation">;</span>

<span class="token comment">-- 在每个死信队列每分钟的时间窗口内，创建消息的聚合视图</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> DLQ_MESSAGE_COUNT_PER_MIN <span class="token keyword">AS</span> \
  <span class="token keyword">SELECT</span> TIMESTAMPTOSTRING<span class="token punctuation">(</span>WINDOWSTART<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">'yyyy-MM-dd HH:mm:ss'</span><span class="token punctuation">)</span> <span class="token keyword">AS</span> START_TS<span class="token punctuation">,</span> \
         SINK_NAME<span class="token punctuation">,</span> \
         GROUP_COL<span class="token punctuation">,</span> \
         <span class="token function">COUNT</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">AS</span> DLQ_MESSAGE_COUNT \
    <span class="token keyword">FROM</span> DLQ_MONITOR \
          WINDOW TUMBLING <span class="token punctuation">(</span>SIZE <span class="token number">1</span> <span class="token keyword">MINUTE</span><span class="token punctuation">)</span> \
 <span class="token keyword">GROUP</span> <span class="token keyword">BY</span> SINK_NAME<span class="token punctuation">,</span> \
          GROUP_COL<span class="token punctuation">;</span>
</code></pre></div><p>这个聚合表可以以交互式的方式进行查询，下面显示了一分钟内每个死信队列中的消息数量：</p> <div class="language- extra-class"><pre class="language-text"><code>ksql&gt; SELECT START_TS, SINK_NAME, DLQ_MESSAGE_COUNT FROM DLQ_MESSAGE_COUNT_PER_MIN;
2019-02-01 02:56:00 | dlq_file_sink_06__01 | 9
2019-02-01 03:10:00 | dlq_file_sink_06__01 | 8
2019-02-01 03:12:00 | dlq_file_sink_06__01 | 5
2019-02-01 02:56:00 | dlq_file_sink_06__02 | 5
2019-02-01 03:12:00 | dlq_file_sink_06__02 | 5
</code></pre></div><p>因为这个表的下面是Kafka主题，所以可以将其路由到期望的任何监控仪表盘，还可以用于驱动告警。假定有几条错误消息是可以接受的，但是一分钟内超过5条消息就是个大问题需要关注：</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> DLQ_BREACH <span class="token keyword">AS</span> \
    <span class="token keyword">SELECT</span> START_TS<span class="token punctuation">,</span> SINK_NAME<span class="token punctuation">,</span> DLQ_MESSAGE_COUNT \
      <span class="token keyword">FROM</span> DLQ_MESSAGE_COUNT_PER_MIN \
     <span class="token keyword">WHERE</span> DLQ_MESSAGE_COUNT<span class="token operator">&gt;</span><span class="token number">5</span><span class="token punctuation">;</span>
</code></pre></div><p>现在又有了一个报警服务可以订阅的<code>DLQ_BREACH</code>主题，当收到任何消息时，可以触发适当的操作（例如通知）。</p> <div class="language- extra-class"><pre class="language-text"><code>ksql&gt; SELECT START_TS, SINK_NAME, DLQ_MESSAGE_COUNT FROM DLQ_BREACH;
2019-02-01 02:56:00 | dlq_file_sink_06__01 | 9
2019-02-01 03:10:00 | dlq_file_sink_06__01 | 8
</code></pre></div><h2 id="kafka-connect哪里没有提供错误处理"><a href="#kafka-connect哪里没有提供错误处理" class="header-anchor">#</a> Kafka Connect哪里没有提供错误处理？</h2> <p>Kafka Connect的错误处理方式，如下表所示：</p> <table><thead><tr><th>连接器生命周期阶段</th> <th>描述</th> <th>是否处理错误？</th></tr></thead> <tbody><tr><td>开始</td> <td>首次启动连接器时，其将执行必要的初始化，例如连接到数据存储</td> <td>无</td></tr> <tr><td>拉取（针对源连接器）</td> <td>从源数据存储读取消息</td> <td>无</td></tr> <tr><td>格式转换</td> <td>从Kafka主题读写数据并对JSON/Avro格式进行序列化/反序列化</td> <td>有</td></tr> <tr><td>单消息转换</td> <td>应用任何已配置的单消息转换</td> <td>有</td></tr> <tr><td>接收（针对接收连接器）</td> <td>将消息写入目标数据存储</td> <td>无</td></tr></tbody></table> <p>注意源连接器没有死信队列。</p> <h2 id="错误处理配置流程"><a href="#错误处理配置流程" class="header-anchor">#</a> 错误处理配置流程</h2> <p>关于连接器错误处理的配置，可以按照如下的流程一步步进阶：</p> <p><img src="https://www.confluent.io/wp-content/uploads/Permutations_Error_Handling_Kafka_Connect_Configuration.png" alt=""></p> <h2 id="总结"><a href="#总结" class="header-anchor">#</a> 总结</h2> <p>处理错误是任何稳定可靠的数据管道的重要组成部分，根据数据的使用方式，可以有两个选项。如果管道任何错误的消息都不能接受，表明上游存在严重的问题，那么就应该立即停止处理（这是Kafka Connect的默认行为）。</p> <p>另一方面，如果只是想将数据流式传输到存储以进行分析或非关键性处理，那么只要不传播错误，保持管道稳定运行则更为重要。这时就可以定义错误的处理方式，推荐的方式是使用死信队列并密切监视来自Kafka Connect的可用JMX指标。
<div class="right-pale"><div class="right-content"><div class="bbox tell-box"><button class="btn btn-circle btn-success right-tell"><i class="fa fa-lg fa-phone"></i></button> <p class="tell-hide">
            18624049226
        </p></div> <div class="bbox weixin-box"><button class="btn btn-circle btn-success right-weixin"><i class="fa fa-weixin"></i></button> <p class="tell-hide" style="padding:5px;"><img src="/img/weixin.jpg"></p></div></div></div></p></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">最后更新时间：:</span> <span class="time">7/22/2020, 2:42:40 PM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/confluent/Kafka-ConvertersSerialization.html" class="prev">
        Kafka Connect深度解读之转换器和序列化
      </a></span> <span class="next"><a href="/confluent/Kafka-CreateDynamicConnectors.html">
        使用Connect API创建自定义Kafka Connect
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"><!----></div></div>
    <script src="/assets/js/app.12c4309e.js" defer></script><script src="/assets/js/3.b95bc49f.js" defer></script><script src="/assets/js/1.5c509afc.js" defer></script><script src="/assets/js/32.81d53af7.js" defer></script><script src="/assets/js/8.85f43835.js" defer></script>
  </body>
</html>
